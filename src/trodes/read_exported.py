#!/usr/bin/env python3
"""
"""
import os
import warnings
import re
from collections import defaultdict
import pathlib
import numpy as np

def parse_exported_file(file_path):
    """
    """
    with open(file_path, 'rb') as f:
        # Check if first line is start of settings block
        if f.readline().decode('ascii').strip() != '<Start settings>':
            raise Exception("Settings format not supported")
        fields = True
        fields_text = {}
        for line in f:
            # Read through block of settings
            if fields:
                line = line.decode('ascii').strip()
                # filling in fields dict
                if line != '<End settings>':
                    vals = line.split(': ')
                    fields_text.update({vals[0].lower(): vals[1]})
                # End of settings block, signal end of fields
                else:
                    fields = False
                    dt = parse_fields(fields_text['fields'])
                    fields_text['data'] = np.zeros([1], dtype = dt)
                    break
        # Reads rest of file at once, using dtype format generated by parse_fields()
        dt = parse_fields(fields_text['fields'])
        data = np.fromfile(f, dt)
        fields_text.update({'data': data})
        return fields_text

# Parses last fields parameter (<time uint32><...>) as a single string
# Assumes it is formatted as <name number * type> or <name type>
# Returns: np.dtype
def parse_fields(field_str):
    """
    """
    # Returns np.dtype from field string
    sep = re.split('\s', re.sub(r"\>\<|\>|\<", ' ', field_str).strip())
    # print(sep)
    typearr = []
    # Every two elmts is fieldname followed by datatype
    for i in range(0,sep.__len__(), 2):
        fieldname = sep[i]
        repeats = 1
        ftype = 'uint32'
        # Finds if a <num>* is included in datatype
        if sep[i+1].__contains__('*'):
            temptypes = re.split('\*', sep[i+1])
            # Results in the correct assignment, whether str is num*dtype or dtype*num
            ftype = temptypes[temptypes[0].isdigit()]
            repeats = int(temptypes[temptypes[1].isdigit()])
        else:
            ftype = sep[i+1]
        try:
            fieldtype = getattr(np, ftype)
        except AttributeError:
            print(ftype + " is not a valid field type.\n")
            exit(1)
        else:
            typearr.append((str(fieldname), fieldtype, repeats))
    return np.dtype(typearr)

def get_key_with_substring(input_dict, substring="", return_first=True):
    """
    """
    keys_with_substring = []
    for key in input_dict.keys():
        if substring in key:
            keys_with_substring.append(key)
    if substring in keys_with_substring:
        return substring
    elif return_first:
        return keys_with_substring[0]
    else:
        return keys_with_substring

def get_all_file_suffixes(file_name):
    """
    Creates a string of the suffixes of a file name that's joined together by "."
    Suffixes will be all the parts of the file name that follows the first "."
    Example: "file.txt.zip.asc" >> "txt.zip.asc"
    
    Args:
        file_name(str): Name of the file

    Returns:
        String of all the suffixes joined by "."
    """
    # Getting all the suffixes in the file name
    # And removing any periods before and after
    stripped_suffixes = [suffix.strip(".") for suffix in pathlib.Path(file_name).suffixes]
    
    if stripped_suffixes:
        return ".".join(stripped_suffixes) 
    # When the file name is just a ".", the stripped suffix is blank
    else:
        return "."

def update_trodes_file_to_data(file_path, file_to_data=None):
    """
    Get the data/metadata froma a Trodes recording file. Save it to a dictionary with the file name as the key. 
    And the name of the data/metadata(sub-key) and the data/metadata point(sub-value) as a subdictionary for the value. 

    Args:
        file_path(str): Path of the Trodes recording file. Can be relative or absolute path.
        file_to_data(dict): Dictionary that had the trodes file name as the key and the 

    Returns:
        Dictionary that has file name keys with a subdictionary of all the different data/metadata from the Trodes recording file.
    """
    # Creating a new dictionary if none is inputted
    if file_to_data is None: 
        file_to_data = defaultdict(dict)
    # Getting just the file name to use as the key
    file_name = os.path.basename(file_path)
    # Getting the absolute file path as metadata
    absolute_file_path = os.path.abspath(file_path)
    try:
        # Reading in the Trodes recording file with the function 
        trodes_recording = parse_exported_file(absolute_file_path)

        file_prefix = get_all_file_suffixes(file_name) 
        print("file prefix: {}".format(file_prefix))
        file_to_data[file_prefix] = trodes_recording
        file_to_data[file_prefix]["absolute_file_path"] = absolute_file_path
        return file_to_data
    except:
        # TODO: Fix format so that file path is included in warning
        warnings.warn("Can not process {}".format(absolute_file_path))
        return None

def get_all_trodes_data_from_directory(parent_directory_path="."):
    """
    Goes through all the files in a directory created by Trodes. 
    Each file is organized into a dictionary that is directory name to the file name to associated data/metadata of the file.
    The structure would look something like: result[current_directory_name][file_name][data_type]

    Args:
        parent_directory_path(str): Path of the directory that contains the Trodes recording files. Can be relative or absolute path.

    Returns:
        Dictionary that has the Trodes directory name as the key and a subdictionary as the values. 
        This subdictionary has all the files as keys with the corresponding data/metadata from the Trodes recording file as values.
    """
    directory_to_file_to_data = defaultdict(dict)
    # Going through each directory
    for item in os.listdir(parent_directory_path):
        item_path = os.path.join(parent_directory_path, item)
        # Getting the directory name to save as the key
        if os.path.isdir(item_path):
            current_directory_name = os.path.basename(item_path)
        # If the item is a file instead of a directory
        else:
            current_directory_name = "."
        directory_prefix = get_all_file_suffixes(current_directory_name) 

        current_directory_path = os.path.join(parent_directory_path, current_directory_name)
        # Going through each file in the directory
        for file_name in os.listdir(current_directory_path):
            file_path = os.path.join(current_directory_path, file_name)
            if os.path.isfile(file_path):
                # Creating a sub dictionary that has file keys and a sub-sub dictionary of data type to data value 
                current_directory_to_file_to_data = update_trodes_file_to_data(file_path=file_path, file_to_data=directory_to_file_to_data[current_directory_name])
                # None will be returned if the file can not be processed
                if current_directory_to_file_to_data is not None:
                    print("directory prefix: {}".format(directory_prefix))
                    directory_to_file_to_data[directory_prefix] = current_directory_to_file_to_data
    return directory_to_file_to_data

